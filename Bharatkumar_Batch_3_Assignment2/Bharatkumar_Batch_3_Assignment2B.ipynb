{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------\n",
    "# Assignment 2B\n",
    "------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "To Rewrite the Backpropagation table with new random values. The Random values need to be generated with Python code.\n",
    "\n",
    "#### A NEURON/PERCEPTRON\n",
    "A NEURON/PERCEPTRON is a special block which can take multiple inputs and produces one output. \n",
    "Each inputs is multiplied with a weight to give importance to an input.\n",
    "\n",
    "\n",
    "#### Step 0:  Load Input and Output \n",
    "Read input and output\n",
    "\n",
    "Python code to Read/load Input and Output values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Create an input matrix with 3 rows and 4 coloumns \n",
    "X = np.array([[1,0,1,0], [1,0,1,1], [0,1,0,1]])\n",
    "# Create an output matrix with 3 rows and 4 coloumns \n",
    "y = np.array([[1],[1],[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table with input and output values\n",
    "Input Matrix\n",
    "|   |   | X |   |\n",
    "|---|---|---|---|\n",
    "| 1 | 0 | 1 | 0 |\n",
    "| 1 | 0 | 1 | 1 |\n",
    "| 0 | 1 | 0 | 1 |\n",
    "\n",
    "Output Matrix\n",
    "| y |\n",
    "|---|\n",
    "| 1 |\n",
    "| 1 |\n",
    "| 0 |\n",
    "\n",
    "\n",
    "#### Step 1: Initialize weights and biases with random values \n",
    "Python code to generate & Initialize weights and biases with random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input layer weights wh:\n",
      "[[0.33658772 0.41819905 0.76677351]\n",
      " [0.73552224 0.80773914 0.70343078]\n",
      " [0.33361382 0.10181493 0.17486657]\n",
      " [0.88065084 0.19883932 0.62752478]]\n",
      "input layer bias bh:\n",
      "[[0.4127476  0.51384118 0.90913379]]\n",
      "output layer weights wout:\n",
      "[[0.68237402]\n",
      " [0.48781596]\n",
      " [0.2770086 ]]\n",
      "output layer bias bout:\n",
      "[[0.36911679]]\n"
     ]
    }
   ],
   "source": [
    "# Generate random values for input layer weights\n",
    "wh = np.random.rand(4,3)\n",
    "# Print the input layer weights\n",
    "print('input layer weights wh:')\n",
    "print(wh)\n",
    "# Generate random values for input layer bias\n",
    "bh = np.random.rand(1,3)\n",
    "# Print the input layer bias\n",
    "print('input layer bias bh:')\n",
    "print(bh)\n",
    "# Generate random values for Output layer weights\n",
    "wout = np.random.rand(3,1)\n",
    "# Print the output layer weights\n",
    "print('output layer weights wout:')\n",
    "print(wout)\n",
    "# Generate random values for Output layer bias\n",
    "bout = np.random.rand(1,1)\n",
    "# Print the output layer bias\n",
    "print('output layer bias bout:')\n",
    "print(bout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table with Input and output weights and biases initialized with random values \n",
    "\n",
    "|    | wh |    |\n",
    "|----|----|----|\n",
    "|0.33658772 | 0.41819905 | 0.76677351 |\n",
    "|0.73552224 | 0.80773914 | 0.70343078 |\n",
    "|0.33361382 | 0.10181493 | 0.17486657 |\n",
    "|0.88065084 | 0.19883932 | 0.62752478 |\n",
    "\n",
    "\n",
    "|   | bh |   |\n",
    "|---|----|---|\n",
    "| 0.4127476 | 0.51384118 | 0.90913379 |\n",
    "\n",
    "\n",
    "| wout |\n",
    "|------|\n",
    "| 0.68237402 |\n",
    "| 0.48781596 |\n",
    "| 0.2770086  |\n",
    "\n",
    "\n",
    "| bout |\n",
    "|------|\n",
    "| 0.36911679 |\n",
    "\n",
    "\n",
    "#### Step 2: Calculate hidden layer input: \n",
    "\n",
    "hidden_layer_input = matrix_dot_product(X,wh) + bh\n",
    "\n",
    "Python code to compute the hidden_layer_input matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_layer_input matrix:\n",
      "[[1.08294914 1.03385516 1.85077387]\n",
      " [1.96359998 1.23269448 2.47829865]\n",
      " [2.02892067 1.52041964 2.24008936]]\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_input = np.dot(X, wh) + bh\n",
    "print('hidden_layer_input matrix:')\n",
    "print(hidden_layer_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hidden_layer_input matrix\n",
    "\n",
    "|        | hidden_layer_input |        |\n",
    "|--------|--------------------|--------|\n",
    "| 1.08294914 | 1.03385516 | 1.85077387 |\n",
    "| 1.96359998 | 1.23269448 | 2.47829865 |\n",
    "| 2.02892067 | 1.52041964 | 2.24008936 |\n",
    "\n",
    "\n",
    "#### Step 3: Perform non-linear transformation on hidden linear input\n",
    "\n",
    "hiddenlayer_activations = sigmoid(hidden_layer_input)\n",
    "Python code to compute the hiddenlayer_activations matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hiddenlayer_activations matrix:\n",
      "[[1.33859549 1.35563329 1.15711553]\n",
      " [1.14035225 1.29150606 1.08388582]\n",
      " [1.13147735 1.21862013 1.10644899]]\n"
     ]
    }
   ],
   "source": [
    "# Sigmoid Function definition\n",
    "def sigmoid(inputs):\n",
    "    #Calculate the sigmoid for the give inputs (array)    \n",
    "    sigmoid_value = 1 / 1 + np.exp(- inputs)     \n",
    "    return sigmoid_value\n",
    "\n",
    "hiddenlayer_activations = sigmoid(hidden_layer_input)\n",
    "print('hiddenlayer_activations matrix:')\n",
    "print(hiddenlayer_activations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hidden layer activations Matrix\n",
    "\n",
    "|     |  hiddenlayer_activations |     |\n",
    "|-----|--------------------------|-----|\n",
    "| 1.33859549 | 1.35563329 | 1.15711553 |\n",
    "| 1.14035225 | 1.29150606 | 1.08388582 |\n",
    "| 1.13147735 | 1.21862013 | 1.10644899 |\n",
    "\n",
    "\n",
    "#### Step 4: Perform linear and non-linear transformation of hidden layer activation at output layer\n",
    "\n",
    "output_layer_input = matrix_dot_product (hiddenlayer_activations * wout ) + bout \n",
    "output = sigmoid(output_layer_input)\n",
    "\n",
    "Python code to compute the output matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_layer_input matrix:\n",
      "[[2.26437007]\n",
      " [2.07752649]\n",
      " [2.04216577]]\n",
      "output matrix:\n",
      "[[1.10389546]\n",
      " [1.12523961]\n",
      " [1.1297474 ]]\n"
     ]
    }
   ],
   "source": [
    "output_layer_input = np.dot(hiddenlayer_activations, wout) + bout\n",
    "output = sigmoid(output_layer_input)\n",
    "print('output_layer_input matrix:')\n",
    "print(output_layer_input)\n",
    "print('output matrix:')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### output Matrix\n",
    "\n",
    "| output     |\n",
    "|------------|\n",
    "| 1.10389546 |\n",
    "| 1.12523961 |\n",
    "| 1.1297474  |\n",
    "\n",
    "\n",
    "#### Step 5: Calculate gradient of Error(E) at output layer\n",
    "\n",
    "E = y-output\n",
    "\n",
    "Python code to compute the Gradient error matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error matrix:\n",
      "[[-0.10389546]\n",
      " [-0.12523961]\n",
      " [-1.1297474 ]]\n"
     ]
    }
   ],
   "source": [
    "E = y - output\n",
    "print('Error matrix:')\n",
    "print(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error(E) Matrix\n",
    "\n",
    "|      E       |\n",
    "|--------------|\n",
    "|  -0.10389546 |\n",
    "|  -0.12523961 |\n",
    "| -1.1297474   |\n",
    "\n",
    "\n",
    "#### Step 6: Compute slope at output and hidden layer\n",
    "\n",
    "`Slope_output_layer= derivatives_sigmoid(output)\n",
    "\n",
    "Slope_hidden_layer = derivatives_sigmoid(hiddenlayer_activations)`\n",
    "\n",
    "Python code to compute the Slope_output_layer and Slope_hidden_layer matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slope_output matrix:\n",
      "[[-0.11468973]\n",
      " [-0.14092457]\n",
      " [-0.14658179]]\n",
      "slope_hidden_layer matrix:\n",
      "[[-0.45324239 -0.48210833 -0.18180082]\n",
      " [-0.160051   -0.37648185 -0.09092265]\n",
      " [-0.14876365 -0.26641489 -0.11778038]]\n"
     ]
    }
   ],
   "source": [
    "def derivatives_sigmoid(inputs):\n",
    "    #Calculate the sigmoid for the give inputs (array)    \n",
    "    sigmoid_derivative_value = inputs * (1-inputs)\n",
    "    return sigmoid_derivative_value\n",
    "\n",
    "slope_output = derivatives_sigmoid(output)\n",
    "slope_hidden_layer = derivatives_sigmoid(hiddenlayer_activations)\n",
    "print('slope_output matrix:')\n",
    "print(slope_output)\n",
    "print('slope_hidden_layer matrix:')\n",
    "print(slope_hidden_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slope_output and Slope_hidden_layer Matrix\n",
    "\n",
    "|Slope_output |\n",
    "|-------------|\n",
    "| -0.11468973 |\n",
    "| -0.14092457 |\n",
    "| -0.14658179 |\n",
    "\n",
    "\n",
    "|         |Slope_hidden_layer|        |\n",
    "|-----------|------------|------------|\n",
    "| -0.45324239 | -0.48210833 | -0.18180082 |\n",
    "| -0.160051   | -0.37648185 | -0.09092265 |\n",
    "| -0.14876365 | -0.26641489 | -0.11778038 |\n",
    "\n",
    "#### Step 7: Compute delta at output layer\n",
    "\n",
    "d_output = E * slope_output * lr\n",
    "\n",
    "Python code to compute the d_output matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_output matrix:\n",
      "[[0.01191574]\n",
      " [0.01764934]\n",
      " [0.1656004 ]]\n"
     ]
    }
   ],
   "source": [
    "# learning rate is represented as lr\n",
    "lr = 1.0\n",
    "d_output = E * slope_output * lr\n",
    "print('d_output matrix:')\n",
    "print(d_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d_output Matrix\n",
    "\n",
    "| d_output    |\n",
    "|-------------|\n",
    "|  0.01191574 |\n",
    "|  0.01764934 |\n",
    "|  0.1656004  |\n",
    "\n",
    "#### Step 8: Calculate Error at hidden layer\n",
    "\n",
    "Error_at_hidden_layer = matrix_dot_product(d_output, wout.Transpose)\n",
    "\n",
    "Python code to compute the Error_at_hidden_layer matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error_at_hidden_layer matrix:\n",
      "[[0.00839725 0.00609956 0.00355832]\n",
      " [0.01243782 0.00903454 0.0052705 ]\n",
      " [0.11670175 0.08476937 0.04945212]]\n"
     ]
    }
   ],
   "source": [
    "error_at_hidden_layer = np.dot(d_output, wout.T)\n",
    "print('error_at_hidden_layer matrix:')\n",
    "print(error_at_hidden_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  error_at_hidden_layer Matrix\n",
    "\n",
    "|          | error_at_hidden_layer |      |\n",
    "|-------------|-------------|-------------|\n",
    "|  0.00839725 | 0.00609956  | 0.00355832  |\n",
    "|  0.01243782 | 0.00903454  | 0.0052705   |\n",
    "|  0.11670175 | 0.08476937  | 0.04945212  |\n",
    "\n",
    "\n",
    "#### Step 9: Compute delta at hidden layer\n",
    "\n",
    "d_hiddenlayer = Error_at_hidden_layer * slope_hidden_layer\n",
    "\n",
    "Python code to compute the d_hiddenlayer matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_hiddenlayer matrix:\n",
      "[[-0.00380599 -0.00294065 -0.0006469 ]\n",
      " [-0.00199069 -0.00340134 -0.00047921]\n",
      " [-0.01736098 -0.02258382 -0.00582449]]\n"
     ]
    }
   ],
   "source": [
    "d_hiddenlayer = error_at_hidden_layer * slope_hidden_layer\n",
    "print('d_hiddenlayer matrix:')\n",
    "print(d_hiddenlayer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  d_hiddenlayer Matrix\n",
    "\n",
    "|             |d_hiddenlayer|              |\n",
    "|-------------|-------------|--------------|\n",
    "|  -0.00380599 | -0.00294065 | -0.0006469  |\n",
    "|  -0.00199069 | -0.00340134 | -0.00047921 |\n",
    "|  -0.01736098 | -0.02258382 | -0.00582449 |\n",
    "\n",
    "\n",
    "\n",
    "#### Step 10: Update weight at both output and hidden layer\n",
    "\n",
    "wout = wout + matrix_dot_product (hiddenlayer_activations.Transpose, d_output) * learning_rate\n",
    "\n",
    "wh = wh+ matrix_dot_product (X.Transpose,d_hiddenlayer) * learning_rate\n",
    "\n",
    "Python code to compute the wout and wh matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wh matrix:\n",
      "[[0.33544676 0.41696048 0.76655644]\n",
      " [0.73210509 0.80332859 0.70230804]\n",
      " [0.33247287 0.10057636 0.1746495 ]\n",
      " [0.87684186 0.1937645  0.62630967]]\n",
      "wout matrix:\n",
      "[[0.727064  ]\n",
      " [0.53596628]\n",
      " [0.32023783]]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "wh = wh + np.dot(X.T, d_hiddenlayer) * learning_rate\n",
    "wout = wout + np.dot(hiddenlayer_activations.T, d_output) * learning_rate\n",
    "print('wh matrix:')\n",
    "print(wh)\n",
    "print('wout matrix:')\n",
    "print(wout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### wh and wout matrix:\n",
    "\n",
    "|             | wh         |            |\n",
    "|-------------|------------|------------|\n",
    "|  0.33544676 | 0.41696048 | 0.76655644 |\n",
    "| 0.73210509  | 0.80332859 | 0.70230804 |\n",
    "|  0.33247287 | 0.10057636 | 0.1746495  |\n",
    "|  0.87684186 | 0.1937645  | 0.62630967 |\n",
    "\n",
    "\n",
    "|    w_out   |\n",
    "|------------|\n",
    "| 0.727064   |\n",
    "| 0.53596628 |\n",
    "| 0.32023783 |\n",
    "\n",
    "\n",
    "#### Update biases at both output and hidden layer\n",
    "\n",
    "bh = bh + sum(d_hiddenlayer, axis=0) * learning_rate\n",
    "bout = bout + sum(d_output, axis=0)*learning_rate\n",
    "\n",
    "Python code to compute the bout and bh matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bh matrix:\n",
      "[[0.40818949 0.50819206 0.90779398]]\n",
      "bout matrix:\n",
      "[[0.40814988]]\n"
     ]
    }
   ],
   "source": [
    "bh = bh + np.sum(d_hiddenlayer, axis=0) * learning_rate\n",
    "bout = bout + np.sum(d_output, axis=0) * learning_rate\n",
    "print('bh matrix:')\n",
    "print(bh)\n",
    "print('bout matrix:')\n",
    "print(bout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bh and bout matrix\n",
    "\n",
    "|            |    b_out   |            |\n",
    "|------------|------------|------------|\n",
    "| 0.40818949 | 0.50819206 | 0.90779398 |\n",
    "\n",
    "\n",
    "|    b_h     |\n",
    "|------------|\n",
    "| 0.40814988 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
